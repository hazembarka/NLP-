{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multilanguage-model_using_tpu.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8a9cf68fb4b4b048c2977ced7238317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e76ef643debb41cbb8eb44b66bb2f2fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9cb31628a0d840dfaa597e526b7ecf79",
              "IPY_MODEL_4b1aff44725e46af97c432eede90c70c"
            ]
          }
        },
        "e76ef643debb41cbb8eb44b66bb2f2fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cb31628a0d840dfaa597e526b7ecf79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d8639337901d47889a46537ae30b9784",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40a2968302ed4ebbbabdc6f3021a5887"
          }
        },
        "4b1aff44725e46af97c432eede90c70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3cd4588d39ed4fa6be8ac95c8f939cb7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:20&lt;00:00, 242kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32f8c587da1d46f8ba5c12fe81b990ab"
          }
        },
        "d8639337901d47889a46537ae30b9784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40a2968302ed4ebbbabdc6f3021a5887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cd4588d39ed4fa6be8ac95c8f939cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32f8c587da1d46f8ba5c12fe81b990ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BQuwlrSioUg",
        "colab_type": "text"
      },
      "source": [
        "# Check Memory in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBBzPO87i6ZH",
        "colab_type": "code",
        "outputId": "5276478a-e908-44ff-c737-a35d54f80dda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        }
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=b3e7f75c8e534994b7abb8903c26156c052554476784e46b77c23512a2d08ae5\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/ba/dda44bbf35b071441635708a3dd568a5ca6bf29f77389f7c7c6818ae9498/transformers-2.7.0-py3-none-any.whl (544kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 10.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 21.0MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 26.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.33)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.33 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.33)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.33->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.33->boto3->transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=d64a6b3e4d3693c9bf83b8ea3194891316dcfe623ec910146bf8b965e2e071f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqD9c76bi0iM",
        "colab_type": "code",
        "outputId": "bceb399c-b8ca-4a05-cc70-6a0c077aebf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 26.3 GB  | Proc size: 158.4 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvArYoUEWCz0",
        "colab_type": "text"
      },
      "source": [
        "# Importations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHdkWLY4Wo5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import OrderedDict, namedtuple\n",
        "import torch.nn as nn\n",
        "from torch.optim import lr_scheduler\n",
        "import joblib\n",
        "\n",
        "import logging\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule, XLMRobertaTokenizer, XLMRobertaModel, XLMRobertaConfig\n",
        "import sys\n",
        "from sklearn import metrics, model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# transformers\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "\n",
        "from transformers import XLNetModel, BertTokenizer, BertConfig\n",
        "from transformers import RobertaModel, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetModel, XLNetTokenizer, XLNetConfig\n",
        "from transformers import DistilBertModel, DistilBertTokenizer, DistilBertConfig\n",
        "from transformers import GPT2Model, GPT2Tokenizer, GPT2Config\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfZwrbviRW6G",
        "colab_type": "text"
      },
      "source": [
        "# Datasets (I hope that this is done ) \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37RxM0qkhsME",
        "colab_type": "text"
      },
      "source": [
        "- BERT: [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "- DistilBERT: [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "- RoBERTa: [CLS] + prefix_space + tokens + [SEP] + padding\n",
        "\n",
        "- XLM: [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "- XLNet: padding + tokens + [SEP] + [CLS]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUP5EmjTmxkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset_class() : \n",
        "  def __init__ (self, comment_text ,tokenizer ,MAX_Len ,targets=None ,train=True ,index=None ,model_name='bert') : \n",
        "    self.model_type = model_name\n",
        "    self.comment_text = comment_text \n",
        "    self.tokenizer = tokenizer \n",
        "    self.max_length = MAX_Len  \n",
        "    self.targets = targets \n",
        "    self.index = index \n",
        "    self.train = train\n",
        "  def __len__(self) :\n",
        "\n",
        "    return len(self.comment_text)\n",
        "\n",
        "  def __getitem__(self,item) : \n",
        "\n",
        "    comment_text = str(self.comment_text[item])\n",
        "    comment_text = \" \".join(comment_text.split())\n",
        "\n",
        "    CLS = self.tokenizer.cls_token\n",
        "    SEP = self.tokenizer.sep_token\n",
        "\n",
        "    if self.model_type in ['roberta']:\n",
        "\n",
        "      tokens = self.tokenizer.tokenize(comment_text, add_prefix_space=True)[:self.max_length - 2]\n",
        "      tokens = [CLS] + tokens + [SEP]\n",
        "\n",
        "    else:\n",
        "\n",
        "      tokens = self.tokenizer.tokenize(comment_text)[:self.max_length - 2]\n",
        "\n",
        "      if self.model_type in ['xlnet']:\n",
        "          tokens = tokens + [SEP] +  [CLS]\n",
        "\n",
        "      else:\n",
        "          tokens = [CLS] + tokens + [SEP]\n",
        "\n",
        "    input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "    segment_ids = [0] * len(tokens)\n",
        "    input_mask = [1] * len(input_ids)\n",
        "    padding = [0] * (self.max_length - len(input_ids))\n",
        "    input_ids += padding\n",
        "    input_mask += padding\n",
        "    segment_ids += padding\n",
        "    if self.train == True : \n",
        "      return {\n",
        "                'ids': torch.tensor(input_ids, dtype=torch.long),\n",
        "                'mask': torch.tensor(input_mask, dtype=torch.long),\n",
        "                'seg_id': torch.tensor(segment_ids, dtype=torch.long),\n",
        "                'targets' : torch.tensor(self.targets[item], dtype=torch.float)            }\n",
        "    else: \n",
        "      return {\n",
        "                'ids': torch.tensor(input_ids, dtype=torch.long),\n",
        "                'mask': torch.tensor(input_mask, dtype=torch.long),\n",
        "                'seg_id': torch.tensor(segment_ids, dtype=torch.long),\n",
        "                'id' : self.index[item]       }\n",
        "            \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdEJNaKm3huF",
        "colab_type": "code",
        "outputId": "811104de-34b6-459b-fde7-15b4cf667175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/comment/train_clean1.csv')\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ExplanationWhy the edits made under my usernam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww ! He matches this background colour I am...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man , I am really not trying to edit war ....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>`` MoreI can not make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You , sir , are my hero . Any chance you remem...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        comment_text  toxic\n",
              "0  ExplanationWhy the edits made under my usernam...      0\n",
              "1  D'aww ! He matches this background colour I am...      0\n",
              "2  Hey man , I am really not trying to edit war ....      0\n",
              "3  `` MoreI can not make any real suggestions on ...      0\n",
              "4  You , sir , are my hero . Any chance you remem...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8kHNLaw3zEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained('/content/drive/My Drive/models') \n",
        "data_set = Dataset_class(train.comment_text,tokenizer,128,train.toxic,model_name='roberta')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb9zD-lG8pc1",
        "colab_type": "code",
        "outputId": "77b90f84-9bbb-4dc8-b721-f50c265f0f4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "data_set[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': tensor([  101, 72997, 10650, 17427, 10103, 25635, 10107, 11050, 10533, 11153,\n",
              "         24934, 23993, 34023, 46671, 10923, 10342, 58831, 50944,   136, 10578,\n",
              "         10342, 10497, 91299, 30164, 12932,   117, 12125, 61091, 10125, 10970,\n",
              "         14524, 10515,   151, 33759, 10160, 10246, 10560, 62532, 72010,   119,\n",
              "         10110, 38881, 10154, 10497, 48107, 10103, 79947, 20849, 10195, 10103,\n",
              "         20220, 13524, 11500,   151, 10345, 18162, 11628,   119, 12844,   119,\n",
              "         20426,   119, 11330,   119, 10377,   102,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
              " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'seg_id': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'targets': tensor(0.)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRQkvANuFAC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertDatasetTest:\n",
        "    def __init__(self,df):\n",
        "        self.comment_text = df.comment_text\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = Max_len\n",
        "        self.id = df['id'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comment_text)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        comment_text = str(self.comment_text[item])\n",
        "        comment_text = \" \".join(comment_text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            comment_text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "        )\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "        \n",
        "        padding_length = self.max_length - len(ids)\n",
        "        \n",
        "        ids = ids + ([0] * padding_length)\n",
        "        mask = mask + ([0] * padding_length)\n",
        "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        \n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'id': self.id[item]\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELowbckzRckH",
        "colab_type": "text"
      },
      "source": [
        "# Models Class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk1HWl3qGUH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class XLMRClassification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear_1 = nn.Linear(768, 768)\n",
        "    self.classification_head = nn.Linear(768, 1)\n",
        "    self.model = XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "    # initializing classification head\n",
        "    self.classification_head.weight.data.normal_(mean=0.0, std=0.04)\n",
        "  def forward(self, inputs_ids ):\n",
        "    transformer_out, _ = self.model(inputs_ids, features_only=True)\n",
        "    out_1 = F.relu(self.linear_1(transformer_out))\n",
        "    out_1 = self.dropout(out_1)\n",
        "    logits = self.classification_head(out_1)\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUX51i1DAQtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class XLNetForJigSaw(XLNetPreTrainedModel):\n",
        "    def __init__(self, config, out_dim):\n",
        "        \n",
        "        super(XLNetForJigSaw, self).__init__(config)\n",
        "        self.attn_type = config.attn_type\n",
        "        self.same_length = config.same_length\n",
        "        self.summary_type = \"last\"\n",
        "\n",
        "        self.transformer = XLNetModel('xlnet-base-cased', output_attentions=False, keep_multihead_output=False)\n",
        "        self.dense = nn.Linear(config.d_model, config.d_model)\n",
        "        self.activation = nn.Tanh()\n",
        "        self.linear = nn.Linear(config.d_model, out_dim, bias=True)\n",
        "        self.apply(self.init_xlnet_weights)\n",
        "\n",
        "    def forward(self, input_ids, seg_id=None, input_mask=None,\n",
        "                mems=None, perm_mask=None, target_mapping=None, inp_q=None,\n",
        "                target=None, output_all_encoded_layers=True, head_mask=None, **kargs):\n",
        "\n",
        "        output, hidden_states, new_mems = self.transformer(input_ids, seg_id, input_mask,\n",
        "                                            mems, perm_mask, target_mapping, inp_q,\n",
        "                                            output_all_encoded_layers, head_mask)\n",
        "        first_token_tensor = output[:, 0]\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "\n",
        "        return self.linear(pooled_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEj00wvV41Yv",
        "colab_type": "text"
      },
      "source": [
        "# Engine GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZifOXeF750l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1QnOAyR3lvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_fn(data_loader, model, optimizer, scheduler):\n",
        "    model.train()\n",
        "\n",
        "    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "        ids = d[\"ids\"]\n",
        "\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "     \n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(ids)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg3jzykt7_Nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_fn(data_loader, model):\n",
        "\n",
        "    model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    with torch.no_grad():\n",
        "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "            input_ids = d[\"input_ids\"]\n",
        "        \n",
        "\n",
        "            \n",
        "            targets = d[\"targets\"]\n",
        "            input_ids = input_ids.to(device, dtype=torch.long)\n",
        "\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "      \n",
        "\n",
        "            outputs = model(\n",
        "                input_ids\n",
        "                )\n",
        "            targets = targets.cpu().detach().numpy().tolist()\n",
        "            outputs = outputs.cpu().detach().numpy().tolist()\n",
        "            fin_targets.extend(targets)\n",
        "            fin_outputs.extend(outputs)    \n",
        "    return fin_outputs, fin_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM4g0Wu2XcEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE =torch.device(\"cuda\")\n",
        "device = torch.device(\"cuda\")\n",
        "def run(model,EPOCHS):\n",
        "    train_dataset = Dataset_class(df_train.comment_text,tokenizer,128,df_train.toxic,model_name='roberta')\n",
        "\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=TRAIN_BATCH_SIZE,\n",
        "        num_workers=4\n",
        "    )\n",
        "    valid_dataset = Dataset_class(df_test.comment_text,tokenizer,128,df_test.toxic,model_name='roberta')\n",
        "\n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=VALID_BATCH_SIZE,\n",
        "        num_workers=1\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    \n",
        "    \n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "\n",
        "    num_train_steps = int(len(train_data_loader)) * EPOCHS\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_train_steps\n",
        "    )\n",
        "\n",
        "\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "    best_accuracy = 0\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_fn(train_data_loader, model, optimizer, scheduler)\n",
        "        outputs, targets = eval_fn(valid_data_loader, model)\n",
        "        outputs = np.array(outputs)\n",
        "        accuracy = metrics.roc_auc_score(targets, outputs)\n",
        "        print(f\"Accuracy Score = {accuracy}\")\n",
        "        scheduler.step()\n",
        "        if accuracy > best_accuracy : \n",
        "          torch.save(model.state_dict(), \"/content/drive/My Drive/models/XLM-roberta/xlm_roberta_model_2.bin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbJ64UunWTrm",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocessing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wowNC1DjH1GB",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data and simple EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf33qZ2YWWOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imblearn\n",
        "print(imblearn.__version__)\n",
        "\n",
        "from imblearn.under_sampling import (RandomUnderSampler, \n",
        "                                     ClusterCentroids,\n",
        "                                     TomekLinks,\n",
        "                                     NeighbourhoodCleaningRule,\n",
        "                                     NearMiss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ORaCeJhZ5qj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
        "X_under, y_under = undersample.fit_resample(train1['comment_text'].values.reshape(-1, 1),train1['toxic'].values.reshape(-1, 1) )\n",
        "train1 = pd.DataFrame(X_under,columns={\"comment_text\"})\n",
        "train1['toxic'] = y_under\n",
        "train1['toxic'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R82NZemMZ8Te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define undersample strategy\n",
        "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
        "X_under, y_under = undersample.fit_resample(train2['comment_text'].values.reshape(-1, 1),train2['toxic'].values.reshape(-1, 1) )\n",
        "train2 = pd.DataFrame(X_under,columns={\"comment_text\"})\n",
        "train2['toxic'] = y_under\n",
        "train2['toxic'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8JcZNrvZ-Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.concat([\n",
        "    train1[['comment_text', 'toxic']],\n",
        "    train2[['comment_text', 'toxic']]\n",
        "])\n",
        "df_train = df_train.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDe1deDzaAAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del train1, train2\n",
        "import gc; gc.collect();\n",
        "\n",
        "df_train.shape, df_valid.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL_UpmVW2ktD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_valid['comment_text'] = df_valid['translated']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz6El1WgsQU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_valid = df_valid[['comment_text','toxic']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DN3EYtRDuY5",
        "colab_type": "text"
      },
      "source": [
        "# Train Phase 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7jdu5nsSq6s",
        "colab_type": "text"
      },
      "source": [
        "# Run XLM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkHTe7w7XpQb",
        "colab_type": "code",
        "outputId": "439dda69-7f08-48f0-8e3a-e0893a5936d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d8a9cf68fb4b4b048c2977ced7238317",
            "e76ef643debb41cbb8eb44b66bb2f2fd",
            "9cb31628a0d840dfaa597e526b7ecf79",
            "4b1aff44725e46af97c432eede90c70c",
            "d8639337901d47889a46537ae30b9784",
            "40a2968302ed4ebbbabdc6f3021a5887",
            "3cd4588d39ed4fa6be8ac95c8f939cb7",
            "32f8c587da1d46f8ba5c12fe81b990ab"
          ]
        }
      },
      "source": [
        "MAX_Len = 192\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 8 \n",
        "EPOCHS = 2\n",
        "tokenizer = transformers.XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8a9cf68fb4b4b048c2977ced7238317",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=5069051, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmrF911V-7P9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train,df_test = train_test_split(train,test_size = 0.1 , random_state = 42 , stratify=train.toxic.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eM6_sGTXdiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model = XLMRClassification()\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAHTFjbwAxU2",
        "colab_type": "code",
        "outputId": "bdc15496-f7f2-48ba-c070-f481ee6483bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "run(model,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/12575 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-60eadc5cd9f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-bf76c194bcc5>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(model, EPOCHS)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mbest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-adab46a75502>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(data_loader, model, optimizer, scheduler)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-20-4b97f4a81a1a>\", line 16, in __getitem__\n    comment_text = str(self.comment_text[item])\n  File \"/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\", line 871, in __getitem__\n    result = self.index.get_value(self, key)\n  File \"/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\", line 4404, in get_value\n    return self._engine.get_value(s, k, tz=getattr(series.dtype, \"tz\", None))\n  File \"pandas/_libs/index.pyx\", line 80, in pandas._libs.index.IndexEngine.get_value\n  File \"pandas/_libs/index.pyx\", line 90, in pandas._libs.index.IndexEngine.get_value\n  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 998, in pandas._libs.hashtable.Int64HashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1005, in pandas._libs.hashtable.Int64HashTable.get_item\nKeyError: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSbBB7TtTu8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_Len = 192\n",
        "TRAIN_BATCH_SIZE = 12\n",
        "VALID_BATCH_SIZE = 8 \n",
        "EPOCHS = 2\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq2bQgRxD4vK",
        "colab_type": "text"
      },
      "source": [
        "# Train Phase 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxMPpXb_D740",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid = pd.read_csv('/content/drive/My Drive/comment/jigsaw_miltilingual_valid_translated.csv')\n",
        "valid['toxic'] = (valid['toxic']>0.5).astype(int)\n",
        "df_valid = valid.copy()\n",
        "valid['comment_text'] = valid['translated']\n",
        "valid=valid[['comment_text','toxic']]\n",
        "valid= valid.append(df_valid[['comment_text','toxic']])\n",
        "df_train , df_valid = train_test_split(valid,test_size = 0.1 , random_state = 42 , stratify=valid.toxic.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcYA-QOwUI3d",
        "colab_type": "code",
        "outputId": "ffc49b58-6fe5-444d-b236-a8fc10257472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/My Drive/models/XLM-roberta/xlm_roberta_model.bin'))\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-c38348b614aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomRoberta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/models/XLM-roberta/xlm_roberta_model.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CustomRoberta:\n\tMissing key(s) in state_dict: \"roberta.embeddings.word_embeddings.weight\", \"roberta.embeddings.position_embeddings.weight\", \"roberta.embeddings.token_type_embeddings.weight\", \"roberta.embeddings.LayerNorm.weight\", \"roberta.embeddings.LayerNorm.bias\", \"roberta.encoder.layer.0.attention.self.query.weight\", \"roberta.encoder.layer.0.attention.self.query.bias\", \"roberta.encoder.layer.0.attention.self.key.weight\", \"roberta.encoder.layer.0.attention.self.key.bias\", \"roberta.encoder.layer.0.attention.self.value.weight\", \"roberta.encoder.layer.0.attention.self.value.bias\", \"roberta.encoder.layer.0.attention.output.dense.weight\", \"roberta.encoder.layer.0.attention.output.dense.bias\", \"roberta.encoder.layer.0.attention.output.LayerNorm.weight\", \"roberta.encoder.layer.0.attention.output.LayerNorm.bias\", \"roberta.encoder.layer.0.intermediate.dense.weight\", \"roberta.encoder.layer.0.intermediate.dense.bias\", \"roberta.encoder.layer.0.output.dense.weight\", \"roberta.encoder.layer.0.output.dense.bias\", \"roberta.encoder.layer.0.output.LayerNorm.weight\", \"roberta.encoder.layer.0.output.LayerNorm.bias\", \"roberta.encoder.layer.1.attention.self.query.weight\", \"roberta.encoder.layer.1.attention.self.query.bias\", \"roberta.encoder.layer.1.attention.self.key.weight\", \"roberta.encoder.layer.1.attention.self.key.bias\", \"roberta.encoder.layer.1.attention.self.value.weight\", \"roberta.encoder.layer.1.attention.self.value.bias\", \"roberta.encoder.layer.1.attention.output.dense.weight\", \"roberta.encoder.lay...\n\tUnexpected key(s) in state_dict: \"module.roberta.embeddings.word_embeddings.weight\", \"module.roberta.embeddings.position_embeddings.weight\", \"module.roberta.embeddings.token_type_embeddings.weight\", \"module.roberta.embeddings.LayerNorm.weight\", \"module.roberta.embeddings.LayerNorm.bias\", \"module.roberta.encoder.layer.0.attention.self.query.weight\", \"module.roberta.encoder.layer.0.attention.self.query.bias\", \"module.roberta.encoder.layer.0.attention.self.key.weight\", \"module.roberta.encoder.layer.0.attention.self.key.bias\", \"module.roberta.encoder.layer.0.attention.self.value.weight\", \"module.roberta.encoder.layer.0.attention.self.value.bias\", \"module.roberta.encoder.layer.0.attention.output.dense.weight\", \"module.roberta.encoder.layer.0.attention.output.dense.bias\", \"module.roberta.encoder.layer.0.attention.output.LayerNorm.weight\", \"module.roberta.encoder.layer.0.attention.output.LayerNorm.bias\", \"module.roberta.encoder.layer.0.intermediate.dense.weight\", \"module.roberta.encoder.layer.0.intermediate.dense.bias\", \"module.roberta.encoder.layer.0.output.dense.weight\", \"module.roberta.encoder.layer.0.output.dense.bias\", \"module.roberta.encoder.layer.0.output.LayerNorm.weight\", \"module.roberta.encoder.layer.0.output.LayerNorm.bias\", \"module.roberta.encoder.layer.1.attention.self.query.weight\", \"module.roberta.encoder.layer.1.attention.self.query.bias\", \"module.roberta.encoder.layer.1.attention.self.key.weight\", \"module.roberta.encoder.layer.1.attention.self.key.bias\", \"module..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8H6SEfQgvBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_Len = 192\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 8 \n",
        "EPOCHS = 2\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained('/content/drive/My Drive/models')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VYP0X80g0r2",
        "colab_type": "code",
        "outputId": "fb50035f-5ea9-44af-80c0-c84daff1b450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "getattr(tqdm, '_instances', {}).clear()\n",
        "run(model,4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [05:05<00:00,  2.95it/s]\n",
            "100%|██████████| 200/200 [00:10<00:00, 18.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score = 0.7437162997922446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [05:05<00:00,  2.95it/s]\n",
            "100%|██████████| 200/200 [00:10<00:00, 18.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score = 0.521680717176448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [05:05<00:00,  2.95it/s]\n",
            "100%|██████████| 200/200 [00:10<00:00, 18.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score = 0.841053608098858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 900/900 [05:05<00:00,  2.95it/s]\n",
            "100%|██████████| 200/200 [00:10<00:00, 18.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score = 0.7807760204633066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLGsbIqhxEu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid = pd.read_csv('/content/drive/My Drive/comment/jigsaw_miltilingual_valid_translated.csv')\n",
        "valid['toxic'] = (valid['toxic']>0.5).astype(int)\n",
        "df_valid = valid.copy()\n",
        "valid['comment_text'] = valid['translated']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njg3BLaDxT6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train , df_valid = train_test_split(valid,test_size = 0.1 , random_state = 42 , stratify=valid.toxic.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTInJ4JAxW20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BERTBaseUncased()\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/models/Bert Model/model_bert.bin'))\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1rj4bFaDoz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ8X1mdBxhgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "getattr(tqdm, '_instances', {}).clear()\n",
        "run(model,4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC-LVcqbD-GH",
        "colab_type": "text"
      },
      "source": [
        "# Pseudo labeling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acUV765mECXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdHtV2e4EDcf",
        "colab_type": "text"
      },
      "source": [
        "# Make Submission "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1RlpG4AGK29",
        "colab_type": "text"
      },
      "source": [
        "## bert "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKVlMHTYFssG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTBaseUncased(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTBaseUncased, self).__init__()\n",
        "\n",
        "        self.bert = transformers.BertModel.from_pretrained('/content/drive/My Drive/models')\n",
        "        self.bert_drop = nn.Dropout(0.3)\n",
        "        self.out = nn.Linear(768 * 2, 1)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            ids,\n",
        "            mask,\n",
        "            token_type_ids\n",
        "    ):\n",
        "        o1, o2 = self.bert(\n",
        "            ids,\n",
        "            attention_mask=mask,\n",
        "            token_type_ids=token_type_ids)\n",
        "        \n",
        "        apool = torch.mean(o1, 1)\n",
        "        mpool, _ = torch.max(o1, 1)\n",
        "        cat = torch.cat((apool, mpool), 1)\n",
        "\n",
        "        bo = self.bert_drop(cat)\n",
        "        p2 = self.out(bo)\n",
        "        return p2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_z3kz3TEHot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BERTBaseUncased()\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/models/model_1.bin'))\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m0cH1fKGKVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGrCo_diGmYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained(\"/content/drive/My Drive/models\", do_lower_case=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-oCrkzB77Ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def prediction (data_loader, model):\n",
        "    model.eval()\n",
        "    fin_outputs = []\n",
        "    indexs=[]\n",
        "    with torch.no_grad():\n",
        "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "            ids = d[\"ids\"]\n",
        "            token_type_ids = d[\"token_type_ids\"]\n",
        "\n",
        "            mask = d[\"mask\"]\n",
        "            index = d['id']\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "\n",
        "            outputs = model(\n",
        "                ids=ids,\n",
        "                mask=mask,\n",
        "                token_type_ids=token_type_ids\n",
        "            )\n",
        "            outputs = outputs.cpu().detach().numpy().tolist()\n",
        "            fin_outputs.extend(outputs)   \n",
        "            indexs.extend(index.tolist()) \n",
        "    return fin_outputs,indexs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h90qiDlZOh8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/My Drive/comment/jigsaw_miltilingual_test_translated.csv')\n",
        "df_test['comment_text'] = df_test['translated']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt49_euaOy5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Max_len = 128\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhIVcJusHaBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuxFl85yK_cY",
        "colab_type": "code",
        "outputId": "05f539b8-6378-4ed4-b2ea-6c814964bfd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_dataset = BertDatasetTest(df_test)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=16,\n",
        "    num_workers=4\n",
        ")\n",
        "o,i = prediction(train_data_loader,model)\n",
        "sub = pd.DataFrame() \n",
        "sub['id'] = i \n",
        "sub['toxic'] = o\n",
        "\n",
        "def f(x) : \n",
        "  return 1 /(1+np.exp(-x[0]))\n",
        "sub['toxic'] = sub['toxic'].apply(f)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3989/3989 [04:15<00:00, 15.62it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J31ZrrBQ4TZ",
        "colab_type": "code",
        "outputId": "5d7f42eb-904a-45e0-b036-03e2aed8ffa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "df_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>content</th>\n",
              "      <th>lang</th>\n",
              "      <th>translated</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Doctor Who adlı viki başlığına 12. doctor olar...</td>\n",
              "      <td>tr</td>\n",
              "      <td>Title named Doctor Who wiki 12. doctor has add...</td>\n",
              "      <td>Title named Doctor Who wiki 12. doctor has add...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Вполне возможно, но я пока не вижу необходимо...</td>\n",
              "      <td>ru</td>\n",
              "      <td>It is possible, but I don't see the need to a...</td>\n",
              "      <td>It is possible, but I don't see the need to a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Quindi tu sei uno di quelli   conservativi  , ...</td>\n",
              "      <td>it</td>\n",
              "      <td>Then you're one of those conservative , who wo...</td>\n",
              "      <td>Then you're one of those conservative , who wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Malesef gerçekleştirilmedi ancak şöyle bir şey...</td>\n",
              "      <td>tr</td>\n",
              "      <td>Unfortunately, it was not performed, but had s...</td>\n",
              "      <td>Unfortunately, it was not performed, but had s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>:Resim:Seldabagcan.jpg resminde kaynak sorunu ...</td>\n",
              "      <td>tr</td>\n",
              "      <td>:Resim:Seldabagcan.jpg the image of the source...</td>\n",
              "      <td>:Resim:Seldabagcan.jpg the image of the source...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63807</th>\n",
              "      <td>63807</td>\n",
              "      <td>No, non risponderò, come preannunciato. Prefer...</td>\n",
              "      <td>it</td>\n",
              "      <td>No, I will not answer, as predicted. I prefer ...</td>\n",
              "      <td>No, I will not answer, as predicted. I prefer ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63808</th>\n",
              "      <td>63808</td>\n",
              "      <td>Ciao, I tecnici della Wikimedia Foundation sta...</td>\n",
              "      <td>it</td>\n",
              "      <td>Hello, the technicians of The Wikimedia Founda...</td>\n",
              "      <td>Hello, the technicians of The Wikimedia Founda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63809</th>\n",
              "      <td>63809</td>\n",
              "      <td>innnazitutto ti ringrazio per i ringraziamenti...</td>\n",
              "      <td>it</td>\n",
              "      <td>innnazitutto thank you for the thanks!! ) is o...</td>\n",
              "      <td>innnazitutto thank you for the thanks!! ) is o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63810</th>\n",
              "      <td>63810</td>\n",
              "      <td>Kaç olumlu oy gerekiyor? Şu an 7 oldu.  Hayır...</td>\n",
              "      <td>tr</td>\n",
              "      <td>How many affirmative votes are required? It's...</td>\n",
              "      <td>How many affirmative votes are required? It's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63811</th>\n",
              "      <td>63811</td>\n",
              "      <td>Te pido disculpas. La verdad es que no me per...</td>\n",
              "      <td>es</td>\n",
              "      <td>I apologise. The truth is that I didn't notic...</td>\n",
              "      <td>I apologise. The truth is that I didn't notic...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63812 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                       comment_text\n",
              "0          0  ...  Title named Doctor Who wiki 12. doctor has add...\n",
              "1          1  ...   It is possible, but I don't see the need to a...\n",
              "2          2  ...  Then you're one of those conservative , who wo...\n",
              "3          3  ...  Unfortunately, it was not performed, but had s...\n",
              "4          4  ...  :Resim:Seldabagcan.jpg the image of the source...\n",
              "...      ...  ...                                                ...\n",
              "63807  63807  ...  No, I will not answer, as predicted. I prefer ...\n",
              "63808  63808  ...  Hello, the technicians of The Wikimedia Founda...\n",
              "63809  63809  ...  innnazitutto thank you for the thanks!! ) is o...\n",
              "63810  63810  ...   How many affirmative votes are required? It's...\n",
              "63811  63811  ...   I apologise. The truth is that I didn't notic...\n",
              "\n",
              "[63812 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M-FfVuDSzzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQrBht5DTCny",
        "colab_type": "code",
        "outputId": "fd2a0649-b1a7-48f7-b97d-f7358c96438d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!ls "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ber_submission1.csv   config.json   pytorch_model.bin\n",
            " ber_submission.csv    model_1.bin   vocab.txt\n",
            "'Bert Model'\t       model_1.zip   XLM-roberta\n",
            " bert_submission.csv   model.zip     xlm_submission.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v86-k_KNTk4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub.to_csv('ber_submission1.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHwTc3A3UAFs",
        "colab_type": "code",
        "outputId": "360b977b-6ea3-4fb7-f14e-6a2030ac502a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "sub"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.164764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63807</th>\n",
              "      <td>63807</td>\n",
              "      <td>0.760219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63808</th>\n",
              "      <td>63808</td>\n",
              "      <td>0.000087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63809</th>\n",
              "      <td>63809</td>\n",
              "      <td>0.177368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63810</th>\n",
              "      <td>63810</td>\n",
              "      <td>0.000083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63811</th>\n",
              "      <td>63811</td>\n",
              "      <td>0.000126</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63812 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id     toxic\n",
              "0          0  0.000823\n",
              "1          1  0.000124\n",
              "2          2  0.164764\n",
              "3          3  0.000113\n",
              "4          4  0.000111\n",
              "...      ...       ...\n",
              "63807  63807  0.760219\n",
              "63808  63808  0.000087\n",
              "63809  63809  0.177368\n",
              "63810  63810  0.000083\n",
              "63811  63811  0.000126\n",
              "\n",
              "[63812 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2ez0MxUGQXV",
        "colab_type": "text"
      },
      "source": [
        "## xlm "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VidtzLcUEkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CustomRoberta()\n",
        "model = nn.DataParallel(model)\n",
        "tokenizer = transformers.XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/models/XLM-roberta/xlm_roberta_model.bin'))\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4lULXK2GRxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_xlm (data_loader, model):\n",
        "    model.eval()\n",
        "    fin_outputs = []\n",
        "    indexs=[]\n",
        "    with torch.no_grad():\n",
        "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "            ids = d[\"ids\"]\n",
        "            mask = d[\"mask\"]\n",
        "            index = d['id']\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=ids,\n",
        "                attention_mask=mask,\n",
        "            )\n",
        "            outputs = outputs.cpu().detach().numpy().tolist()\n",
        "            fin_outputs.extend(outputs)   \n",
        "            indexs.extend(index.tolist()) \n",
        "    return fin_outputs,indexs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6zsJfy3GSPw",
        "colab_type": "code",
        "outputId": "676cfe08-7212-4d8e-ab7d-f2e73739e0e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_dataset = xlmDatasetTest(df_test)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=16,\n",
        "    num_workers=4\n",
        ")\n",
        "o,i = prediction_xlm(train_data_loader,model)\n",
        "sub = pd.DataFrame() \n",
        "sub['id'] = i \n",
        "sub['toxic'] = o\n",
        "\n",
        "def f(x) : \n",
        "  return 1 /(1+np.exp(-x[0]))\n",
        "sub['toxic'] = sub['toxic'].apply(f)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3989/3989 [06:43<00:00,  9.89it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naWB0_mhXLxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQGXV4F_GSyF",
        "colab_type": "text"
      },
      "source": [
        "# Xln"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKmRN-tgGTds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}