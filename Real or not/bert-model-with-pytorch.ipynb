{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Model with Pytorch \n",
    "\n",
    "This notebook is basic on Abhishek Thakur YouTube video \"Training Sentiment Model Using BERT and Serving it with Flask API\" you can find the video here : https://www.youtube.com/watch?v=hinZO--TEk4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UInSvrNSZPn1"
   },
   "source": [
    "# Import libraries and Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers \n",
    "import torch.nn as nn \n",
    "import torch \n",
    "from tqdm import tqdm\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "id": "KQlMlebvZRwP",
    "outputId": "cfcde3ed-a3aa-4fd3-a54e-1a030ea9f0fd"
   },
   "outputs": [],
   "source": [
    "MAX_Len = 512 \n",
    "TRAIN_BATCH_SIZE =8 \n",
    "VALID_BATCH_SIZE = 4\n",
    "BERT_PATH = '../input/bert-base-uncased'\n",
    "TOKENZIER = transformers.BertTokenizer.from_pretrained(BERT_PATH ,do_lower_case = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cQ1utk8X9vj"
   },
   "source": [
    "# Creat Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yP43ulvRYsOm"
   },
   "outputs": [],
   "source": [
    "class BertBaseUncased(nn.Module) :\n",
    "    def __init__(self) : \n",
    "        super(BertBaseUncased,self).__init__() \n",
    "        self.bert = transformers.BertModel.from_pretrained(BERT_PATH) \n",
    "        self.bert_drop = nn.Dropout(0.4) \n",
    "        self.out = nn.Linear(768,1) \n",
    "    def forward(self,ids,mask,token_type_ids) : \n",
    "        out1,out2 = self.bert( \n",
    "            ids , \n",
    "            attention_mask = mask , \n",
    "            token_type_ids = token_type_ids \n",
    "        )\n",
    "        bo = self.bert_drop(out2) \n",
    "        output = self.out(bo) \n",
    "        return output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AiJIGkNRcCj1"
   },
   "source": [
    "# Data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y1O6Qblqdsb4"
   },
   "outputs": [],
   "source": [
    "class BERTDataset : \n",
    "    def __init__(self,df) : \n",
    "        \n",
    "        self.text = df['text'].values\n",
    "        self.target = df['target'].values \n",
    "        self.tokenizer = TOKENZIER \n",
    "        self.max_len = MAX_Len \n",
    "    def __len__(self) : \n",
    "        return len(self.text) \n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.text[item])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                None,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len\n",
    "            )\n",
    "\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        padding_length = self.max_len - len(ids)\n",
    "        ids = ids + ([0] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "\n",
    "        return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "                'targets': torch.tensor(self.target[item], dtype=torch.float)\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAGxYHXzgxQ3"
   },
   "source": [
    "# Engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BXGFFS2jhmd"
   },
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Asq4vE1FjfTS"
   },
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, optimizer, scheduler):\n",
    "    model.train()\n",
    "\n",
    "    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        targets = d[\"targets\"]\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C55CMeLFgzyK"
   },
   "outputs": [],
   "source": [
    " def eval_fn(data_loader, model):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids = d[\"ids\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            targets = d[\"targets\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v4Rs8SOml3qr"
   },
   "source": [
    "# Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xbDUKu42l3Y8"
   },
   "outputs": [],
   "source": [
    "DEVICE =torch.device(\"cuda\")\n",
    "device = torch.device(\"cuda\")\n",
    "def run(model,EPOCHS):\n",
    "    dfx = pd.read_csv('../input/nlp-getting-started/train.csv').fillna(\"none\")\n",
    "    df_train, df_valid = model_selection.train_test_split(\n",
    "        dfx,\n",
    "        test_size=0.1,\n",
    "        random_state=42,\n",
    "        stratify=dfx.target.values\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    train_dataset = BERTDataset(\n",
    "        df_train\n",
    "    )\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_dataset = BERTDataset(\n",
    "        df_valid\n",
    "\n",
    "    )\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "        num_workers=1\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    \n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "    ]\n",
    "\n",
    "    num_train_steps = int(len(train_data_loader)) * EPOCHS\n",
    "    optimizer = AdamW(optimizer_parameters, lr=1e-5)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_train_steps\n",
    "    )\n",
    "\n",
    "\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "    best_accuracy = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_fn(train_data_loader, model, optimizer, scheduler)\n",
    "        outputs, targets = eval_fn(valid_data_loader, model)\n",
    "        outputs = np.array(outputs) >= 0.5\n",
    "        accuracy = metrics.accuracy_score(targets, outputs)\n",
    "        print(f\"Accuracy Score = {accuracy}\")\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "p_1Oq1uK1qqg",
    "outputId": "1c930398-6332-43e0-b723-d8b48286f9ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 857/857 [06:23<00:00,  2.23it/s]\n",
      "100%|██████████| 191/191 [00:14<00:00, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.8543307086614174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertBaseUncased()\n",
    "model.to(device)\n",
    "getattr(tqdm, '_instances', {}).clear()\n",
    "run(model,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G0St4ri3JRfg"
   },
   "source": [
    "# Make Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nndLPPZ4bU8i"
   },
   "outputs": [],
   "source": [
    "def sentence_prediction(sentence):\n",
    "    tokenizer = TOKENZIER\n",
    "    max_len = MAX_Len\n",
    "    text = str(sentence)\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len\n",
    "    )\n",
    "\n",
    "    ids = inputs[\"input_ids\"]\n",
    "    mask = inputs[\"attention_mask\"]\n",
    "    token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "    padding_length = max_len - len(ids)\n",
    "    ids = ids + ([0] * padding_length)\n",
    "    mask = mask + ([0] * padding_length)\n",
    "    token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "\n",
    "    ids = torch.tensor(ids, dtype=torch.long).unsqueeze(0)\n",
    "    mask = torch.tensor(mask, dtype=torch.long).unsqueeze(0)\n",
    "    token_type_ids = torch.tensor(token_type_ids, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    ids = ids.to(DEVICE, dtype=torch.long)\n",
    "    token_type_ids = token_type_ids.to(DEVICE, dtype=torch.long)\n",
    "    mask = mask.to(DEVICE, dtype=torch.long)\n",
    "\n",
    "    outputs = model(\n",
    "        ids=ids,\n",
    "        mask=mask,\n",
    "        token_type_ids=token_type_ids\n",
    "    )\n",
    "\n",
    "    outputs = torch.sigmoid(outputs).cpu().detach().numpy()\n",
    "    return outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/nlp-getting-started/test.csv')\n",
    "test['target'] = test['text'].apply(sentence_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>0.881398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>0.886369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>0.877925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>0.961192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>0.967887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "      <td>0.798764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "      <td>0.940204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "      <td>0.975234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "      <td>0.846939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "      <td>0.683835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         0     NaN      NaN   \n",
       "1         2     NaN      NaN   \n",
       "2         3     NaN      NaN   \n",
       "3         9     NaN      NaN   \n",
       "4        11     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text    target  \n",
       "0                    Just happened a terrible car crash  0.881398  \n",
       "1     Heard about #earthquake is different cities, s...  0.886369  \n",
       "2     there is a forest fire at spot pond, geese are...  0.877925  \n",
       "3              Apocalypse lighting. #Spokane #wildfires  0.961192  \n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan  0.967887  \n",
       "...                                                 ...       ...  \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...  0.798764  \n",
       "3259  Storm in RI worse than last hurricane. My city...  0.940204  \n",
       "3260  Green Line derailment in Chicago http://t.co/U...  0.975234  \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...  0.846939  \n",
       "3262  #CityofCalgary has activated its Municipal Eme...  0.683835  \n",
       "\n",
       "[3263 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test[['id','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sub['target'] = sub['target'].round().astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "3258    1\n",
       "3259    1\n",
       "3260    1\n",
       "3261    1\n",
       "3262    1\n",
       "Name: target, Length: 3263, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['target'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using keywords for prediction improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Disaster Probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wreckage</th>\n",
       "      <td>39</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debris</th>\n",
       "      <td>37</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>derailment</th>\n",
       "      <td>39</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outbreak</th>\n",
       "      <td>40</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oil%20spill</th>\n",
       "      <td>38</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>typhoon</th>\n",
       "      <td>38</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide%20bombing</th>\n",
       "      <td>33</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide%20bomber</th>\n",
       "      <td>31</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bombing</th>\n",
       "      <td>29</td>\n",
       "      <td>0.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide%20bomb</th>\n",
       "      <td>35</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Count  Disaster Probability\n",
       "keyword                                       \n",
       "wreckage              39              1.000000\n",
       "debris                37              1.000000\n",
       "derailment            39              1.000000\n",
       "outbreak              40              0.975000\n",
       "oil%20spill           38              0.973684\n",
       "typhoon               38              0.973684\n",
       "suicide%20bombing     33              0.969697\n",
       "suicide%20bomber      31              0.967742\n",
       "bombing               29              0.931034\n",
       "suicide%20bomb        35              0.914286"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../input/nlp-getting-started/train.csv')\n",
    "train = train.fillna('None')\n",
    "ag = train.groupby('keyword').agg({'text':np.size, 'target':np.mean}).rename(columns={'text':'Count', 'target':'Disaster Probability'})\n",
    "ag.sort_values('Disaster Probability', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bombing',\n",
       " 'debris',\n",
       " 'derailment',\n",
       " 'nuclear%20disaster',\n",
       " 'oil%20spill',\n",
       " 'outbreak',\n",
       " 'rescuers',\n",
       " 'suicide%20bomb',\n",
       " 'suicide%20bomber',\n",
       " 'suicide%20bombing',\n",
       " 'typhoon',\n",
       " 'wreckage']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_list = list(ag[(ag['Count']>2) & (ag['Disaster Probability']>=0.9)].index)\n",
    "keyword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:9114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3331: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = test['id'][test.keyword.isin(keyword_list)].values\n",
    "sub['target'][sub['id'].isin(ids)] = 1\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you find this kernel useful and enjoyable.\n",
    "\n",
    "\n",
    "and here you will find my notebook about working with text data in pandas : https://www.kaggle.com/nhoues1997/working-with-text-data-in-pandas\n",
    "\n",
    "\n",
    "Your comments and feedback are most welcome. \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Real_or_Not_! (1).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
